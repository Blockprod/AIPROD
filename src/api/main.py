"""
API REST FastAPI pour AIPROD V33
Endpoints pour l'orchestration du pipeline, gestion des entrÃ©es et exposition des rÃ©sultats.
"""

import time
from contextlib import asynccontextmanager
from fastapi import (
    FastAPI,
    HTTPException,
    Response,
    WebSocket,
    WebSocketDisconnect,
    Depends,
)
from prometheus_fastapi_instrumentator import Instrumentator
from pydantic import BaseModel, ConfigDict, Field
from typing import Any, Dict, Optional, List
import asyncio
from src.orchestrator.state_machine import StateMachine
from src.api.functions.input_sanitizer import InputSanitizer
from src.api.functions.financial_orchestrator import FinancialOrchestrator
from src.api.functions.technical_qa_gate import TechnicalQAGate
from src.utils.metrics_collector import MetricsCollector, prom_router
from src.utils.monitoring import logger
from src.config.secrets import load_secrets, get_secret, mask_secret
from src.auth.firebase_auth import get_firebase_authenticator
from src.api.auth_middleware import (
    verify_token,
    optional_verify_token,
    AuthMiddleware,
    require_auth,
)
from src.security.audit_logger import get_audit_logger, AuditEventType, audit_log
from src.api.presets import (
    get_preset,
    get_all_presets,
    apply_preset_to_request,
    estimate_cost_for_preset,
    PresetTier,
)
from src.api.cost_estimator import get_full_cost_estimate, get_job_actual_costs
from src.api.icc_manager import get_job_manager, JobState
from src.db.models import get_session_factory, JobState as DBJobState
from src.db.job_repository import JobRepository
from src.pubsub.client import get_pubsub_client, PubSubClient
import os

# Database session factory
_db_session_factory = None


def get_db_session():
    """Get database session."""
    global _db_session_factory
    if _db_session_factory is None:
        db_url = os.getenv(
            "DATABASE_URL", "postgresql://aiprod:password@localhost:5432/aiprod_v33"
        )
        _db_session_factory, _ = get_session_factory(db_url)
    return _db_session_factory()


# ðŸ” Lifespan context manager pour startup/shutdown
@asynccontextmanager
async def lifespan(app: FastAPI):
    """GÃ¨re le cycle de vie de l'application (startup/shutdown)."""
    # Startup
    logger.info("ðŸ” Initializing security components...")

    # Charger les secrets depuis GCP Secret Manager / .env
    load_secrets()
    logger.info("âœ… Secrets loaded successfully")

    # Initialiser Firebase Authentication
    auth = get_firebase_authenticator()
    if auth.enabled:
        logger.info("âœ… Firebase Authentication initialized")
    else:
        logger.warning("âš ï¸  Firebase Authentication disabled (development mode)")

    # Initialiser Audit Logger
    audit_logger = get_audit_logger()
    logger.info("âœ… Audit logging initialized")
    logger.info("ðŸ” Security initialization complete")

    yield

    # Shutdown
    logger.info("ðŸ›‘ Shutting down...")


app = FastAPI(
    title="AIPROD V33 API",
    description="Pipeline de gÃ©nÃ©ration vidÃ©o IA avec orchestration, agents et QA",
    version="1.0.0",
    lifespan=lifespan,
)

# Ajout du router Prometheus /metrics
app.include_router(prom_router)

# Instrumentation Prometheus
Instrumentator().instrument(app).expose(app)

# ðŸ” Ajouter le middleware d'authentification
app.add_middleware(AuthMiddleware)


# DTOs pour les entrÃ©es/sorties
class PipelineRequest(BaseModel):
    """SchÃ©ma de requÃªte pour le pipeline."""

    content: str
    priority: str = "low"
    lang: str = "en"
    preset: Optional[str] = Field(
        default=None,
        description="Preset Ã  utiliser: quick_social, brand_campaign, premium_spot",
    )
    duration_sec: Optional[int] = Field(
        default=30, description="DurÃ©e vidÃ©o souhaitÃ©e en secondes"
    )

    model_config = ConfigDict(extra="allow")


class CostEstimateRequest(BaseModel):
    """SchÃ©ma de requÃªte pour estimation de coÃ»ts."""

    content: str
    duration_sec: int = 30
    preset: Optional[str] = None
    complexity: str = "standard"


class CostEstimateResponse(BaseModel):
    """SchÃ©ma de rÃ©ponse estimation de coÃ»ts."""

    aiprod_optimized: float
    runway_alone: float
    savings: float
    savings_percent: float
    quality_guarantee: float
    backend_selected: str
    breakdown: Dict[str, float]
    value_proposition: str


class PipelineResponse(BaseModel):
    """SchÃ©ma de rÃ©ponse du pipeline."""

    status: str
    state: str
    data: Dict[str, Any]


# Instances globales
state_machine = StateMachine()
input_sanitizer = InputSanitizer()
financial_orchestrator = FinancialOrchestrator()
technical_qa_gate = TechnicalQAGate()
metrics_collector = MetricsCollector()
job_manager = get_job_manager()


# Favicon minimaliste (1x1 px) pour Ã©viter les 404 locales
FAVICON_BYTES = (
    b"\x00\x00\x01\x00\x01\x00\x10\x10\x10\x00\x00\x00\x00\x00"
    b"\x28\x01\x00\x00\x16\x00\x00\x00\x28\x00\x00\x00\x10\x00"
    b"\x00\x00\x10\x00\x00\x00\x01\x00\x04\x00\x00\x00\x00\x00"
    b"\x80\x00\x00\x00\xc4\x0e\x00\x00\xc4\x0e\x00\x00\x00\x00"
    b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"
    b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"
    b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"
    b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"
    b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"
    b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"
    b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"
    b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"
    b"\x00\x00\x00\x00\x00\x00\x00\x00\xff\xff\xff\xff\xff\xff"
    b"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff"
    b"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff"
    b"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff"
    b"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff"
    b"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff"
    b"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff"
    b"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff"
    b"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff"
    b"\xff\xff\xff\xff\xff\xff\xff\xff"
)


# Route d'accueil simple pour Ã©viter le 404 sur /
@app.get("/")
async def root() -> Dict[str, str]:
    logger.info("GET /")
    return {
        "status": "ok",
        "name": "AIPROD V33 API",
        "docs": "/docs",
        "openapi": "/openapi.json",
    }


@app.get("/health")
async def health() -> Dict[str, str]:
    """
    Endpoint de santÃ© de l'API.
    Returns:
        Dict[str, str]: Status de l'API.
    """
    logger.info("GET /health")
    return {"status": "ok"}


@app.post("/pipeline/run")
async def run_pipeline(
    request: PipelineRequest, user: dict = Depends(verify_token)
) -> Dict[str, Any]:
    """
    Lance l'exÃ©cution du pipeline complet de maniÃ¨re asynchrone.

    ðŸ” AUTHENTIFICATION REQUISE
    ðŸš€ ASYNC: Retourne immÃ©diatement un job_id, traitement en arriÃ¨re-plan

    Supporte les presets: quick_social, brand_campaign, premium_spot

    Args:
        request (PipelineRequest): RequÃªte avec paramÃ¨tres du pipeline.
        user: Utilisateur authentifiÃ© (injectÃ© par verify_token)
    Returns:
        Dict avec job_id et status "queued"
    """
    start_time = time.time()

    try:
        user_id = user.get("uid", user.get("email", "anonymous"))
        user_email = user.get("email", "")

        logger.info(
            f"POST /pipeline/run from {user_email} with content={request.content[:50]}, preset={request.preset}"
        )

        # RÃ©cupÃ©rer les donnÃ©es de requÃªte
        request_data = request.model_dump()

        # Ajouter l'ID utilisateur aux mÃ©tadonnÃ©es
        request_data["_user_id"] = user_id
        request_data["_user_email"] = user_email

        # Appliquer le preset si spÃ©cifiÃ©
        preset_name = request.preset or "quick_social"
        if request.preset:
            preset = get_preset(request.preset)
            if not preset:
                raise HTTPException(
                    status_code=400,
                    detail=f"Preset inconnu: {request.preset}. Disponibles: quick_social, brand_campaign, premium_spot",
                )
            request_data = apply_preset_to_request(request_data, request.preset)
            logger.info(
                f"Preset '{request.preset}' appliquÃ©: mode={preset.pipeline_mode}, quality={preset.quality_threshold}"
            )

        # Ajouter estimation de coÃ»t initiale
        cost_estimate = get_full_cost_estimate(
            content=request.content,
            duration_sec=request.duration_sec or 30,
            preset=request.preset,
        )
        request_data["_cost_estimate"] = cost_estimate["aiprod_optimized"]

        # Sanitize inputs
        sanitized = input_sanitizer.sanitize(request_data)

        # ðŸ” P1.2: Create job in PostgreSQL
        db_session = get_db_session()
        try:
            job_repo = JobRepository(db_session)
            job = job_repo.create_job(
                content=request.content,
                preset=preset_name,
                user_id=user_id,
                job_metadata={
                    "email": user_email,
                    "duration_sec": request.duration_sec or 30,
                    "priority": request.priority,
                    "lang": request.lang,
                    "cost_estimate": cost_estimate,
                    "sanitized_content": sanitized.get("content", request.content),
                },
            )
            job_id = job.id
            logger.info(f"Job {job_id} created in PostgreSQL for user {user_id}")
        finally:
            db_session.close()

        # ðŸš€ P1.2: Publish to Pub/Sub for async processing
        try:
            pubsub_client = get_pubsub_client()
            message_id = pubsub_client.publish_job(
                job_id=str(job_id),
                user_id=user_id,
                content=sanitized.get("content", request.content),
                preset=preset_name,
                metadata={
                    "email": user_email,
                    "duration_sec": request.duration_sec or 30,
                    "priority": request.priority,
                    "lang": request.lang,
                    "cost_estimate": cost_estimate["aiprod_optimized"],
                },
            )
            logger.info(f"Job {job_id} published to Pub/Sub (msg_id={message_id})")
        except Exception as pubsub_error:
            # If Pub/Sub fails, update job status to FAILED
            logger.error(f"Pub/Sub publish failed for job {job_id}: {pubsub_error}")
            db_session = get_db_session()
            try:
                job_repo = JobRepository(db_session)
                job_repo.update_job_state(
                    str(job_id), "FAILED", reason=f"Pub/Sub error: {str(pubsub_error)}"
                )
            finally:
                db_session.close()
            raise HTTPException(
                status_code=503, detail="Queue service temporarily unavailable"
            )

        # ðŸ” Audit logging de succÃ¨s
        audit_logger = get_audit_logger()
        latency_ms = (time.time() - start_time) * 1000
        audit_logger.log_api_call(
            endpoint="/pipeline/run",
            method="POST",
            user_id=user_email,
            status_code=202,
            duration_ms=latency_ms,
        )

        # Return immediately with job_id (async pattern)
        return {
            "status": "queued",
            "job_id": job_id,
            "message": "Job submitted for processing",
            "cost_estimate": cost_estimate,
            "check_status_at": f"/pipeline/job/{job_id}",
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Pipeline error: {e}")
        metrics_collector.record_error(str(e))

        # ðŸ” Audit logging d'erreur
        audit_logger = get_audit_logger()
        latency_ms = (time.time() - start_time) * 1000
        audit_logger.log_api_call(
            endpoint="/pipeline/run",
            method="POST",
            user_id=user.get("email"),
            status_code=500,
            duration_ms=latency_ms,
        )

        raise HTTPException(status_code=500, detail=str(e))


@app.get("/pipeline/job/{job_id}")
async def get_job_status(
    job_id: str, user: dict = Depends(verify_token)
) -> Dict[str, Any]:
    """
    RÃ©cupÃ¨re l'Ã©tat d'un job spÃ©cifique.

    ðŸ” AUTHENTIFICATION REQUISE

    Args:
        job_id: Identifiant unique du job
        user: Utilisateur authentifiÃ© (injectÃ© par verify_token)
    Returns:
        Dict avec les dÃ©tails du job (status, history, result si terminÃ©)
    """
    user_id = user.get("uid", user.get("email", "anonymous"))

    db_session = get_db_session()
    try:
        job_repo = JobRepository(db_session)
        job = job_repo.get_job(job_id)

        if not job:
            raise HTTPException(status_code=404, detail=f"Job {job_id} not found")

        # Security: Only job owner can access
        if job.user_id != user_id:
            logger.warning(
                f"User {user_id} attempted to access job {job_id} owned by {job.user_id}"
            )
            raise HTTPException(status_code=403, detail="Access denied")

        # Build response
        response = {
            "job_id": job.id,
            "status": job.current_state,
            "created_at": job.created_at.isoformat(),
            "updated_at": job.updated_at.isoformat(),
            "preset": job.preset,
            "content_preview": (
                getattr(job, "content", "")[:100] + "..."
                if len(getattr(job, "content", "")) > 100
                else getattr(job, "content", "")
            ),
        }

        # Add state history
        response["state_history"] = [
            {
                "state": record.state,
                "entered_at": record.entered_at.isoformat(),
                "metadata": record.state_metadata,
            }
            for record in job.state_history
        ]

        # Add result if completed
        if job.result:
            response["result"] = {
                "success": job.result.success,
                "output": job.result.output,
                "completed_at": (
                    job.result.completed_at.isoformat()
                    if job.result.completed_at
                    else None
                ),
                "error_message": job.result.error_message,
                "execution_time_ms": job.result.execution_time_ms,
            }

        # Add retry info if applicable
        if job.retry_count > 0:
            response["retry_count"] = job.retry_count

        logger.info(f"Job status retrieved: {job_id} -> {job.current_state}")
        return response

    finally:
        db_session.close()


@app.get("/pipeline/jobs")
async def list_user_jobs(
    user: dict = Depends(verify_token),
    status: Optional[str] = None,
    limit: int = 20,
    offset: int = 0,
) -> Dict[str, Any]:
    """
    Liste les jobs de l'utilisateur.

    ðŸ” AUTHENTIFICATION REQUISE

    Args:
        user: Utilisateur authentifiÃ©
        status: Filtrer par statut (optionnel)
        limit: Nombre max de rÃ©sultats (dÃ©faut: 20)
        offset: DÃ©calage pour pagination
    Returns:
        Dict avec liste des jobs et mÃ©tadonnÃ©es de pagination
    """
    user_id = user.get("uid", user.get("email", "anonymous"))

    db_session = get_db_session()
    try:
        job_repo = JobRepository(db_session)
        jobs = job_repo.list_jobs(
            user_id=user_id, state_filter=status, limit=limit, offset=offset
        )

        return {
            "jobs": [
                {
                    "job_id": job["id"],
                    "status": job["current_state"],
                    "preset": job.get("preset"),
                    "content_preview": (
                        job.get("content", "")[:50] + "..."
                        if len(job.get("content", "")) > 50
                        else job.get("content", "")
                    ),
                    "created_at": job.get("created_at"),
                }
                for job in jobs
            ],
            "limit": limit,
            "offset": offset,
            "count": len(jobs),
        }
    finally:
        db_session.close()


@app.get("/pipeline/status")
async def pipeline_status(
    user: Optional[dict] = Depends(optional_verify_token),
) -> Dict[str, str]:
    """
    RÃ©cupÃ¨re l'Ã©tat actuel du pipeline.
    Returns:
        Dict[str, str]: Ã‰tat du pipeline.
    """
    logger.info(
        f"GET /pipeline/status from {user.get('email') if user else 'anonymous'}"
    )
    audit_logger = get_audit_logger()
    audit_logger.log_api_call(
        endpoint="/pipeline/status",
        method="GET",
        user_id=user.get("email") if user else "anonymous",
        status_code=200,
    )
    return {"state": state_machine.state.name}


@app.get("/favicon.ico")
async def favicon() -> Response:
    """Favicon inline pour Ã©viter le 404 des navigateurs."""
    return Response(content=FAVICON_BYTES, media_type="image/x-icon")


@app.get("/icc/data")
async def get_icc_data() -> Dict[str, Any]:
    """
    Endpoint ICC (Interface Client Collaboratif) pour exposer les donnÃ©es mÃ©moire.
    Returns:
        Dict[str, Any]: DonnÃ©es exposÃ©es Ã  l'ICC.
    """
    logger.info("GET /icc/data")
    return state_machine.data


@app.get("/metrics")
async def get_metrics(
    user: Optional[dict] = Depends(optional_verify_token),
) -> Dict[str, Any]:
    """
    Endpoint pour rÃ©cupÃ©rer les mÃ©triques de performance.
    Returns:
        Dict[str, Any]: MÃ©triques du pipeline.
    """
    logger.info(f"GET /metrics from {user.get('email') if user else 'anonymous'}")
    audit_logger = get_audit_logger()
    audit_logger.log_api_call(
        endpoint="/metrics",
        method="GET",
        user_id=user.get("email") if user else "anonymous",
        status_code=200,
    )
    return (
        metrics_collector.get_internal_metrics()
    )  # CORRECTION: get_internal_metrics() au lieu de get_metrics()


@app.get("/alerts")
async def get_alerts() -> Dict[str, Any]:
    """
    Endpoint pour rÃ©cupÃ©rer les alertes actives.
    Returns:
        Dict[str, Any]: Alertes dÃ©clenchÃ©es.
    """
    logger.info("GET /alerts")
    alerts = metrics_collector.check_alerts()
    return {"alerts": alerts}


@app.post("/financial/optimize")
async def optimize_financial(
    manifest: Dict[str, Any], user: Optional[dict] = Depends(optional_verify_token)
) -> Dict[str, Any]:
    """
    Endpoint pour l'optimisation financiÃ¨re.
    Args:
        manifest (Dict[str, Any]): Manifeste Ã  optimiser.
    Returns:
        Dict[str, Any]: RÃ©sultat d'optimisation.
    """
    logger.info(
        f"POST /financial/optimize from {user.get('email') if user else 'anonymous'}"
    )
    audit_logger = get_audit_logger()
    audit_logger.log_api_call(
        endpoint="/financial/optimize",
        method="POST",
        user_id=user.get("email") if user else "anonymous",
        status_code=200,
    )
    return financial_orchestrator.optimize(manifest)


@app.post("/qa/technical")
async def validate_technical(
    manifest: Dict[str, Any], user: Optional[dict] = Depends(optional_verify_token)
) -> Dict[str, Any]:
    """
    Endpoint pour la validation technique.
    Args:
        manifest (Dict[str, Any]): Manifeste Ã  valider.
    Returns:
        Dict[str, Any]: Rapport de validation.
    """
    logger.info(f"POST /qa/technical from {user.get('email') if user else 'anonymous'}")
    audit_logger = get_audit_logger()
    audit_logger.log_api_call(
        endpoint="/qa/technical",
        method="POST",
        user_id=user.get("email") if user else "anonymous",
        status_code=200,
    )
    return technical_qa_gate.validate(manifest)


# ========================================
# PHASE 1 OPTIMISATION: PRESETS & COST ESTIMATE
# ========================================


@app.get("/presets")
async def list_presets() -> Dict[str, Any]:
    """
    Liste tous les presets disponibles avec leurs configurations.

    Returns:
        Dict avec les presets: quick_social, brand_campaign, premium_spot
    """
    logger.info("GET /presets")
    return {
        "presets": get_all_presets(),
        "usage": "Ajoutez 'preset': 'quick_social' dans votre requÃªte /pipeline/run",
    }


@app.get("/presets/{preset_name}")
async def get_preset_details(preset_name: str) -> Dict[str, Any]:
    """
    RÃ©cupÃ¨re les dÃ©tails d'un preset spÃ©cifique.

    Args:
        preset_name: Nom du preset (quick_social, brand_campaign, premium_spot)

    Returns:
        Configuration du preset avec estimation de coÃ»t
    """
    logger.info(f"GET /presets/{preset_name}")
    preset = get_preset(preset_name)
    if not preset:
        raise HTTPException(
            status_code=404,
            detail=f"Preset '{preset_name}' non trouvÃ©. Disponibles: quick_social, brand_campaign, premium_spot",
        )

    return {
        "name": preset.name,
        "description": preset.description,
        "pipeline_mode": preset.pipeline_mode,
        "quality_threshold": preset.quality_threshold,
        "max_duration_sec": preset.max_duration_sec,
        "max_cost_per_minute": preset.max_cost_per_minute,
        "allow_icc": preset.allow_icc,
        "consistency_cache": preset.consistency_cache,
        "multi_review": preset.multi_review,
        "priority": preset.priority,
        "estimated_cost_30s": preset.estimated_cost,
        "cost_estimate_for_durations": {
            "10s": estimate_cost_for_preset(preset_name, 10),
            "30s": estimate_cost_for_preset(preset_name, 30),
            "60s": estimate_cost_for_preset(preset_name, 60),
        },
    }


@app.post("/cost-estimate")
async def estimate_cost(request: CostEstimateRequest) -> Dict[str, Any]:
    """
    Estime le coÃ»t d'une gÃ©nÃ©ration vidÃ©o avec comparaison concurrents.

    Retourne:
        - CoÃ»t AIPROD optimisÃ©
        - CoÃ»t Runway direct (benchmark)
        - Ã‰conomies rÃ©alisÃ©es
        - Garantie qualitÃ©

    Args:
        request: Contenu, durÃ©e, preset optionnel

    Returns:
        Estimation dÃ©taillÃ©e avec breakdown et comparaison
    """
    logger.info(
        f"POST /cost-estimate for duration={request.duration_sec}s, preset={request.preset}"
    )

    estimate = get_full_cost_estimate(
        content=request.content,
        duration_sec=request.duration_sec,
        preset=request.preset,
        complexity=request.complexity,
    )

    return estimate


@app.get("/job/{job_id}/costs")
async def get_job_costs(job_id: str) -> Dict[str, Any]:
    """
    RÃ©cupÃ¨re les coÃ»ts rÃ©els d'un job terminÃ©.

    Args:
        job_id: Identifiant du job

    Returns:
        CoÃ»ts estimÃ©s vs rÃ©els avec breakdown
    """
    logger.info(f"GET /job/{job_id}/costs")

    # RÃ©cupÃ©rer les donnÃ©es du job depuis la state machine
    job_data = state_machine.data

    if not job_data:
        raise HTTPException(
            status_code=404, detail=f"Job '{job_id}' non trouvÃ© ou pas encore terminÃ©"
        )

    return get_job_actual_costs(job_data)


# ========================================
# PHASE 2: INTERACTIVE CREATIVE CONTROL (ICC)
# ========================================


class ManifestUpdateRequest(BaseModel):
    """SchÃ©ma pour mise Ã  jour du manifest."""

    shot_list: Optional[List[str]] = None
    scenes: Optional[List[str]] = None
    duration: Optional[int] = None
    audio_style: Optional[str] = None
    camera_movements: Optional[List[str]] = None


@app.get("/jobs")
async def list_jobs() -> Dict[str, Any]:
    """
    Liste tous les jobs (pour admin/debug).

    Returns:
        Liste des jobs avec leurs Ã©tats
    """
    logger.info("GET /jobs")
    return {
        "jobs": job_manager.get_all_jobs(),
        "total": len(job_manager.get_all_jobs()),
    }


@app.get("/job/{job_id}")
async def get_job(job_id: str) -> Dict[str, Any]:
    """
    RÃ©cupÃ¨re les dÃ©tails complets d'un job.

    Args:
        job_id: Identifiant du job

    Returns:
        DÃ©tails complets du job incluant manifest, coÃ»ts, rÃ©sultats
    """
    logger.info(f"GET /job/{job_id}")

    job = await job_manager.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail=f"Job '{job_id}' non trouvÃ©")

    return job_manager.to_dict(job)


@app.get("/job/{job_id}/manifest")
async def get_job_manifest(job_id: str) -> Dict[str, Any]:
    """
    RÃ©cupÃ¨re le production_manifest d'un job.
    Permet au client de voir et prÃ©parer les modifications.

    Args:
        job_id: Identifiant du job

    Returns:
        Production manifest avec champs Ã©ditables marquÃ©s
    """
    logger.info(f"GET /job/{job_id}/manifest")

    job = await job_manager.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail=f"Job '{job_id}' non trouvÃ©")

    if not job.production_manifest:
        raise HTTPException(
            status_code=400,
            detail="Manifest pas encore disponible. Job doit Ãªtre en Ã©tat WAITING_APPROVAL.",
        )

    return {
        "job_id": job_id,
        "state": job.state.value,
        "manifest": job.production_manifest,
        "consistency_markers": job.consistency_markers,  # Read-only
        "editable_fields": [
            "shot_list",
            "scenes",
            "duration",
            "audio_style",
            "camera_movements",
        ],
        "locked_fields": ["consistency_markers"],
        "can_edit": job.state == JobState.WAITING_APPROVAL,
        "edits_history": job.edits_history,
    }


@app.patch("/job/{job_id}/manifest")
async def update_job_manifest(
    job_id: str, updates: ManifestUpdateRequest
) -> Dict[str, Any]:
    """
    Met Ã  jour le production_manifest d'un job.
    Seul possible quand le job est en Ã©tat WAITING_APPROVAL.

    Args:
        job_id: Identifiant du job
        updates: Champs Ã  mettre Ã  jour (shot_list, scenes, duration, etc.)

    Returns:
        Manifest mis Ã  jour
    """
    logger.info(f"PATCH /job/{job_id}/manifest")

    job = await job_manager.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail=f"Job '{job_id}' non trouvÃ©")

    if job.state != JobState.WAITING_APPROVAL:
        raise HTTPException(
            status_code=400,
            detail=f"Impossible de modifier le manifest en Ã©tat '{job.state.value}'. Doit Ãªtre 'waiting_approval'.",
        )

    # Appliquer les mises Ã  jour
    updates_dict = updates.model_dump(exclude_none=True)
    if not updates_dict:
        raise HTTPException(status_code=400, detail="Aucune mise Ã  jour fournie")

    updated_job = await job_manager.update_manifest(job_id, updates_dict)
    if not updated_job:
        raise HTTPException(
            status_code=500, detail="Ã‰chec de la mise Ã  jour du manifest"
        )

    return {
        "job_id": job_id,
        "status": "updated",
        "manifest": updated_job.production_manifest,
        "changes": updates_dict,
        "edits_count": len(updated_job.edits_history),
    }


@app.post("/job/{job_id}/approve")
async def approve_job(job_id: str) -> Dict[str, Any]:
    """
    Approuve un job pour lancer le rendu.
    DÃ©clenche la transition WAITING_APPROVAL â†’ RENDERING.

    Args:
        job_id: Identifiant du job

    Returns:
        Confirmation d'approbation et nouvel Ã©tat
    """
    logger.info(f"POST /job/{job_id}/approve")

    job = await job_manager.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail=f"Job '{job_id}' non trouvÃ©")

    if job.state != JobState.WAITING_APPROVAL:
        raise HTTPException(
            status_code=400,
            detail=f"Impossible d'approuver en Ã©tat '{job.state.value}'. Doit Ãªtre 'waiting_approval'.",
        )

    approved_job = await job_manager.approve_job(job_id)
    if not approved_job:
        raise HTTPException(status_code=500, detail="Ã‰chec de l'approbation du job")

    approval_ts = (
        approved_job.approval_timestamp.isoformat()
        if approved_job.approval_timestamp
        else None
    )

    return {
        "job_id": job_id,
        "status": "approved",
        "state": approved_job.state.value,
        "approval_timestamp": approval_ts,
        "message": "Job approuvÃ©. Le rendu va dÃ©marrer automatiquement.",
        "next_state": "rendering",
    }


@app.post("/job/{job_id}/cancel")
async def cancel_job(job_id: str, reason: str = "User cancelled") -> Dict[str, Any]:
    """
    Annule un job.

    Args:
        job_id: Identifiant du job
        reason: Raison de l'annulation

    Returns:
        Confirmation d'annulation
    """
    logger.info(f"POST /job/{job_id}/cancel")

    job = await job_manager.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail=f"Job '{job_id}' non trouvÃ©")

    if job.state in [JobState.DELIVERED, JobState.CANCELLED]:
        raise HTTPException(
            status_code=400,
            detail=f"Impossible d'annuler un job en Ã©tat '{job.state.value}'.",
        )

    cancelled_job = await job_manager.cancel_job(job_id, reason)
    if not cancelled_job:
        raise HTTPException(status_code=500, detail="Ã‰chec de l'annulation du job")

    return {
        "job_id": job_id,
        "status": "cancelled",
        "state": cancelled_job.state.value,
        "reason": reason,
    }


@app.websocket("/ws/job/{job_id}")
async def websocket_job_updates(websocket: WebSocket, job_id: str):
    """
    WebSocket pour recevoir les mises Ã  jour temps rÃ©el d'un job.

    Events:
        - state_changed: Transition d'Ã©tat du job
        - manifest_updated: Modification du manifest
        - cost_updated: Mise Ã  jour de l'estimation de coÃ»t
        - approved: Job approuvÃ©
        - qa_completed: Rapport QA disponible
        - cancelled: Job annulÃ©

    Usage:
        ws://host/ws/job/{job_id}
    """
    await websocket.accept()
    logger.info(f"WebSocket connected for job {job_id}")

    job = await job_manager.get_job(job_id)
    if not job:
        await websocket.send_json({"error": f"Job '{job_id}' non trouvÃ©"})
        await websocket.close()
        return

    # S'abonner aux mises Ã  jour
    await job_manager.subscribe(job_id, websocket)

    # Envoyer l'Ã©tat initial
    await websocket.send_json(
        {
            "event": "connected",
            "job_id": job_id,
            "state": job.state.value,
            "timestamp": job.updated_at.isoformat(),
        }
    )

    try:
        while True:
            # Garder la connexion ouverte et Ã©couter les messages du client
            data = await websocket.receive_text()

            # Le client peut envoyer des pings pour garder la connexion active
            if data == "ping":
                await websocket.send_json({"event": "pong"})
            elif data == "status":
                # Renvoyer l'Ã©tat actuel
                current_job = await job_manager.get_job(job_id)
                if current_job:
                    await websocket.send_json(
                        {
                            "event": "status",
                            "job_id": job_id,
                            "state": current_job.state.value,
                            "approved": current_job.approved,
                        }
                    )

    except WebSocketDisconnect:
        logger.info(f"WebSocket disconnected for job {job_id}")
        await job_manager.unsubscribe(job_id, websocket)
    except Exception as e:
        logger.error(f"WebSocket error for job {job_id}: {e}")
        await job_manager.unsubscribe(job_id, websocket)


@app.get("/icc/stats")
async def get_icc_stats() -> Dict[str, Any]:
    """
    Statistiques ICC pour monitoring.

    Returns:
        Stats sur les jobs: total, par Ã©tat, taux d'approbation
    """
    logger.info("GET /icc/stats")

    jobs = job_manager.get_all_jobs()

    # Compter par Ã©tat
    state_counts = {}
    approved_count = 0
    for job in jobs:
        state = job["state"]
        state_counts[state] = state_counts.get(state, 0) + 1
        if job["approved"]:
            approved_count += 1

    return {
        "total_jobs": len(jobs),
        "jobs_by_state": state_counts,
        "approved_count": approved_count,
        "approval_rate": round(approved_count / len(jobs) * 100, 1) if jobs else 0,
    }
